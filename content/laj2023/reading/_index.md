---
# Title, summary, and page position.
linktitle: Reading Assignments
summary: Assigned reading for class, organized chronologically.
weight: 20
# icon: book-reader
# icon\_pack: fas
draft: false
# Page metadata.
title: Reading Assignments
date: '2022-08-14T00:00:00Z'
# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
type: book # Do not modify.
toc: false
---
To allow for this course to be flexible in response to the pace and dynamics of our in-class discussions, reading assignments will be scheduled on a rolling basis. To allow you enough time to read the assigned material, I plan to post reading assignments at least one week in advance of class. Once I have posted a reading assignment for a particular day, I will not change the assignment by adding more reading for that day.

Do not forget to submit your reading response the evening before class. Details about your weekly reading responses can be found on the [assignments and grading page][1].

## Lesson 01 - Aug. 22

### The scope and scale of legal algorithms

Our first class will address some foundational questions. 

- Why does this class exist and why are you taking it? 
- How are algorithms, artificial intelligence, and machine learning already affecting legal decision-making? What are the benefits? What concerns does this development raise?



_Assignment:_

Part One: In prior versions of this course, I’ve devoted time on the first day for students to introduce themselves and share what topics they’re interested in learning about in the class. I’d still like to take the time for you to introduce yourselves. But I have an additional assignment I’d like you to do before class. Instead of sharing aloud with the class what you’d like to get out of the class, I’d like you to ask a large language model (such as [ChatGPT](https://chat.openai.com/)) to write your introduction to this class based upon your background and interests. On the first day, each student will share with the rest of the class the personal introduction that the LLM has crafted for them — along with any commentary you may have about the LLM‘s statements. In turn, I will share with the class ChatGPT’s vision of a class entitled “Law, Justice, and Algorithms” and share how our class differs from the AI model’s prediction.

Part Two: Use some of the language from the introduction that the LLM has created for you as a prompt for [Dall-E](https://openai.com/dall-e-2) (or another text-to-image model like StableDiffusion or MidJourney) to create an image.

Please email me both the LLM text and image as part of your reading response. You are welcome to create multiple versions and send me your preferred text and image.

_Readings:_

[**DOWNLOAD ALL READINGS FOR LESSON 01**](Lesson01.zip)

AI in the Criminal Justice System
<br> Epic.org
<br> Read all.

How the Police Use Facial Recognition, and Where It Falls Short
<br> Jennifer Valentino-DeVries, New York Times (Jan. 22 2020)
<br> Read all.

Chicago’s “Race-Neutral” Traffic Cameras Ticket Black and Latino Drivers the Most
<br> Emily Hopkins & Melissa Sanchez, ProPublica (Jan. 11, 2022)
<br> Read all.

The Coming Collision Between Autonomous Vehicles and the Liability System <br> Gary Marchant and Rachel Lindor, 52 Santa Clara L. Rev. 1321 (2012) 
<br> Read pages 1321-1330.

The Promise and Perils of Algorithmic Lenders’ Use of Big Data <br> Matthew Adam Bruckner, 93 Chi.-Kent L. Rev. 3 (2018) 
<br> Read pages 31-38.

DeepFakes: A Looming Challenge for Privacy, Democracy, and National Security <br> Citron & Chesney (Scholarly Common at BU, 2019) 
<br> Read pages 1768-86.

Sanctions Issued in Case Where Lawyers Cited ChatGPT-Hallucinated Precedents<br> Eugene Volokh, Volokh Conspiracy (June 22, 2023)<br> Read all.



## Lesson 02 - Aug. 29

### An introduction to machine learning
In this class, we will discuss how the field of machine learning has developed, what it looks like now, and how it may look in the future. With a firmer understanding of what machine learning is, we can address the question of whether we need distinct legal or regulatory frameworks for governing algorithmic decision-making systems or whether the “law of the algorithm” is an unnecessarily specific instance of more general principles.

_Readings:_

[**DOWNLOAD ALL READINGS FOR LESSON 02**](Lesson02.zip)

Machine Learning: A Primer: an introduction for both technical and non-technical readers
<br> Lizzie Turner, Medium: Artificial Intelligence (May 26, 2018)
<br> Read all.

An Introduction to Statistical Learning with Applications in R
<br> Gareth James, Daniela Witten, Trevor Hastie, & Robert Tibshirani (2021)
<br> Read Introduction pages 1-9 (stop at “Who Should Read This Book?), 15-42.

Anatomy of an A.I. System
<br> Kate Crawford & Vladan Joler (2018)
<br> Read all.

Do Artifacts Have Politics?
<br> Langdon Winner, Deadlus Volume 109(1) (1980)
<br> Read all.

Cyberspace and the Law of the Horse
<br> Frank Easterbrook, University of Chicago Legal Forum 207 (1996) 
<br> Read all.


## Lesson 03 - Sep. 5

### The aspirations of legal algorithms
What concepts and tools do computational resources offer for realizing legal values and policies? What cautions and objections should lawyers and communities sharpen in the face of increasing use of computational and algorithmic tools in public and private settings?

_Readings:_

[**DOWNLOAD ALL READINGS FOR LESSON 03**](Lesson03.zip)

Prediction Policy Problems
<br> Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer, American Economic Review (2015) 
<br> Read pages 491-95.

A Guide to Solving Social Problems with Machine Learning
<br> Jon Kleinberg, Jens Ludwig, and Sendhil Mullainathan, Harvard Business Review (Dec. 8, 2016)
<br> Read all.

Of prediction and policy
<br> The Economist (Aug. 20, 2016)
<br> Read all.

Biased Algorithms Are Easier to Fix Than Biased People
<br> Sendhil Mullainathan, N.Y. Times (Dec. 6, 2019)
<br> Read all.

Want Less-Biased Decisions? Use Algorithms.
<br> Alex P. Miller, Harvard Business Review (2018)
<br> Read all.

## Lesson 04 - Sep. 12

### Fairness and discrimination
Recent developments in A.I. and machine learning raise questions about how fairness, equality, and nondiscrimination should be understood, defined, assessed, and advanced. As you make your way through this week’s readings, keep the following questions in mind:

- What are the contrasting conceptions of fairness at work in these different sources? 
- How should we reconcile competing concerns of accuracy and equity?
- How should an understanding of historic and systemic inequality influence the approach to incorporating machine learning into legal decision-making?
- Do risk scores pose the same or different problems depending on the decision-making context (e.g., access to credit, eligibility for pretrial release without bail, parole eligibility, policing, child welfare, and so on)?

 
_Readings:_

[**DOWNLOAD ALL READINGS FOR LESSON 04**](Lesson04.zip)

Two Conceptions of Procedural Fairness
<br> Cass R. Sunstein, Social Research, Vol. 73, No. 2 (Summer 2006).
<br> Read all. 

Discrimination in the Age of Algorithms
<br> Jon Kleinberg, Jens Ludwi, Sendhil Mullainathan and Cass R. Sunstein, Journal of Legal Analysis (2018).
<br> Read pages 113-146.

Fairness and Abstraction in Sociotechnical Systems
<br> Andrew W. Selbst, dana boyd, Sorelle Friedler, Suresh Venkatusabramanian, and Janet Vertsei, ACM Conference on Fairness, Accountability, and Transparency (2019)
<br> Read all.

Where fairness fails: data, algorithms, and the limits of antidiscrimination discourse
<br> Anna Lauren Hoffmann, Information, Communications, and Society (2019)
<br> Read all.

## Lesson 05 - Sep. 19

### Case study on risk assessments

What was your attitude toward risk assessments before doing these readings? What changed and why?

If you had to align yourself with one of the authors or between multiple authors, who would they be? How would your perspective differ from theirs?

What do you think of the “perfect is the enemy of good” argument from the “Open Letter”? Does your answer depend on a conception of risk assessments as either a positive incremental change or a distraction from other interventions?

What do you make of Mayson’s argument to use risk assessments to predict needs and intervene in positive ways?
Mayson’s article leaves out what to do for pretrial incarceration in the absence of risk assessments. How do you expect that the open letter authors would respond? Would you buy their response? How would you approach the challenge that Mayson leaves unanswered?

[**DOWNLOAD ALL READINGS FOR LESSON 05**](Lesson05.zip)

Machine Bias
<br> Julia Angwin, et al., ProPublica (May 22, 2016).
<br> Read the whole thing.

False Positives, False Negatives, and False Analyses: A Rejoinder to ‘Machine Bias: There’s Software Used Across the Country to Predict Future Criminals. And It’s Biased Against Blacks,’
<br> Anthony W. Flores et al., 80:2 Federal Probation (Sept. 2016).
<br> Read the whole thing.

More than 100 Civil Rights, Digital Justice, and Community-Based Organizations Raise Concerns About Pretrial Risk Assessment
<br> The Leadership Conference on Civil and Human Rights (2018).
<br> Read the whole thing.

Updated Position on Pretrial Risk Assessments Tools
<br> The Pretrial Justice Institute, (2020).
<br> Read the whole thing.

Open Letter to the Pretrial Justice Institute
<br> James Austin, Sarah L Desmarais & John Monahan, (2020).
<br> Read the whole thing.

The Accuracy, Equity, and Jurisprudence of Criminal Risk Assessment
<br> Sharad Goel et al. (2018). 
<br> Read pages 1-4, 7-12.

Bias In, Bias Out
<br> Sandra G. Mayson, 128 Yale L.J. 2218 (2019). 
<br> Read the introduction, pages 2221-27.

Algorithmic Risk Assessments and The Double-edged Sword of Youth
<br> Megan T Stevenson & Christopher Slobogin, (2018). 
<br> Read the introduction, pages 1-3.

## Lesson 06 - Sep. 26

### Transparency, interpretability, and explainability

In this session we will discuss different approaches to achieve explainability, both from a legal and technical perspective. We will learn about the difference between interpretable algorithms and non-interpretable algorithms, and the difference between transparency ex-ante and transparency ex-post including different auditing methods. We will also discuss the tradeoff between transparency and accuracy, and how balance between the two can be achieved. 

Questions to consider:

- Does a requirement of transparency or explanation in the use of algorithms in decision-making promote fairness? 
- How would it work and what would be limitations? 
- How should different legal contexts require different transparency practices?

[**DOWNLOAD ALL READINGS FOR LESSON 06**](Lesson06.zip)

Transparency and Accountability in ML-Enabled Systems
<br> Christian Kästner, Medium, 2022
<br> Read the whole thing.

Interpretability and explainability
<br> Christian Kästner, Medium, 2021
<br> Read the whole thing.

The Mythos of Model Interpretability
<br> Zachary C. Lipton, 2016 ICML Workshop on Human Interpretability in Machine Learning 
<br> Read the whole thing.

Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead
<br> Cynthia Rudin, Nature (2019)
<br> Read the whole thing.

The Intuitive Appeal of Explanable Machines
<br> Andrew D. Selbts and Solon Barocas, 87 Fordham L. Rev., 1085 (2018).
<br> Read 1087-1099.

The Hidden Costs of Automated Thinking
<br> Jonathan Zittrain, New Yorker (2019).
<br> Read the whole thing.

## Lesson 07 - Oct. 3

To be determined.

## Lesson 08 - Oct. 17

To be determined.

## Lesson 09 - Oct. 24

To be determined.

## Lesson 10 - Oct. 31

To be determined.

## Lesson 11 - Nov. 7

To be determined.

## Lesson 12 - Nov. 14

Student Presentations (No reading assignment)

## Lesson 13 - Nov. 21

Student Presentations (No reading assignment)



[1]:	/../../laj2023/syllabus/grading