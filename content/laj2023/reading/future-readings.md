---
# Title, summary, and page position.
linktitle: Future Reading Assignments
summary: Assigned reading for class, organized chronologically.
weight: 20
# icon: book-reader
# icon\_pack: fas
draft: true
# Page metadata.
title: Reading Assignments
date: '2022-08-14T00:00:00Z'
# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
type: book # Do not modify.
toc: true
---

# For Chat GPT Lesson
Video: How GPT/ChatGPT Work - An Understandable Introduction to the Technology 
<br> Harry Surden
<br> https://www.youtube.com/watch?v=IMAhwv5dn8E


# From last year:



## Lesson 05 - Feb. 15

### Prediction and probability

Many legal concepts and practices are rooted in the language and logic of prediction and probability. Before issuing a preliminary injunction, a judge must predict whether the plaintiffs will win their case on the merits. Police must have probable cause for many arrests, searches, and seizures to be constitutionally permissible. Child welfare agencies triage investigations of suspected neglect based on predictions of which claims will be substantiated, while public housing authorities manage waitlists for housing based on predictions of who will use public housing for the shortest length of time before living independently.

Across legal systems nationwide, algorithmic predictions are replacing or informing predictions traditionally made by humans. Today, algorithms can deny a person government food benefits, send a social worker to investigate a home, or ban a person from flying on commercial airlines. In many places, criminal procedure is now algorithmic from start to finish. Based on predictions of wrongdoing, algorithms encourage police to investigate, judges to incarcerate, probation to surveil, and parole boards to deny release.

As you go through this week’s readings, ask yourself about the compatibility of traditional legal concepts and emerging algorithmic systems. How much is a legal idea like “probable cause” governed by our understanding of probability? As we develop or encounter systems that consider probability much more rigorously than judges or police traditionally would, how much should statistical thinking govern our decision-making? Are there some legal concepts that can be reduced to numerical probability and some that should not be understood in purely probabilistic terms? Why? When is it fair to make a legal judgment that depends upon a prediction about someone based on that person’s similarity to a broader group? Is it ever possible to make a prediction about someone that doesn’t rely upon their similarity to a broader group?

_Readings:_

[**DOWNLOAD ALL READINGS FOR LESSON 05**](Lesson05.zip)

[Law and the Crystal Ball](https://openyls.law.yale.edu/bitstream/handle/20.500.13051/2423/Law_and_the_Crystal_Ball_Predicting_Behavior_with_Statistical_Inference_and_Individualized_Judgment.pdf?sequence=2)
<br> Barbara Underwood, 88 Yale L.J. 1408 (1979).
<br> Read the first part, pages 1408-1420.

[Naked Statistical Evidence of Liability: Is Subjective Probability Enough?](https://psycnet.apa.org/record/1992-33520-001)
<br> Gary L. Wells, J. Personality & Social Psych. 62:3 (1992).
<br> Read the whole thing.

[On Individual Risk](https://arxiv.org/abs/1406.5540)
<br> Philip Dawid, arXiv (2017).
<br> Read the whole thing.

[The Prediction of Violent Behavior: Toward a Second Generation of Theory and Policy](https://ajp.psychiatryonline.org/doi/epdf/10.1176/ajp.141.1.10)
<br>John Monahan, 141 American Journal of Psychiatry 10 (1984).
<br> Read the whole thing.

[Predicting Proportionality: The Case for Algorithmic Sentencing](https://www.tandfonline.com/doi/full/10.1080/0731129X.2018.1552359)
<br> Vincent Chiao, 37 Criminal Justice Ethics 238 (2018). 
<br> Read introduction, pages 238-40.

[Situating methods in the magic of Big Data and AI](https://www.tandfonline.com/doi/full/10.1080/03637751.2017.1375130)
<br> M. C. Elish & danah boyd, 85 Communication Monographs 57 (2018). 
<br> Read the introduction pages 57-58 and pages 67-72, starting with “Faith in Prediction.”






## Lesson 08 - Mar. 22

### Regulation Part One

This class and the next will exam legal regimes that could be used to govern or regulate the use of algorithms. Our first class will examine the “Blueprint for an A.I. Bill of Rights” that the White House put out this past fall and also the challenge of regulating deep fakes.

As A.I. and machine learning proliferates, what regulations are required? Are our institutions up to the task or is technology’s disruptive power overblown? Where might governmental oversight succeed and where might it fail? What would underegulation and overregulation look like in this space? How could we measure it? What existing rights should the government protect? What new rights ought to be protected in an age of automation?

[**DOWNLOAD ALL READINGS FOR LESSON 08**](Lesson08.zip)

Please note that the download link above does not include the assigned podcast episode in the .zip file.

[Podcast: Suresh Venkatasubramanian: An AI Bill of Rights](https://thegradientpub.substack.com/p/suresh-venkatasubramanian-an-ai-bill#details)
<br> The Gradient, (2023).
<br> Listen from 43:50 to the end. But feel free to listen to whole thing if you want, lots of good stuff.

[Blueprint for an A.I. Bill of Rights](https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf)
<br> Read pages 5-7, 15-29, 40-52.

[DeepFakes: A Looming Challenge for Privacy, Democracy, and National Security](https://scholarship.law.bu.edu/cgi/viewcontent.cgi?article=1640&context=faculty_scholarship)
<br> Danielle K. Citron & Robert Chesney, Calif. L. Rev. (2019) 
<br> Read 1768-1786 (Section II: Costs & Benefits).

[Responding to Deepfakes and Disinformation](https://www.theregreview.org/2021/08/14/saturday-seminar-responding-deepfakes-disinformation/)
<br> Soojin Jeong, Margaret Sturtevant, & Karis Stephen, The Regulatory Review (2021).
<br> Read the whole thing.

[Congress Should Not Rush to Regulate Deepfakes](https://www.eff.org/deeplinks/2019/06/congress-should-not-rush-regulate-deepfakes)
<br> Hayley Tsukayama, India Mckinney, & Jamie Williams, Electronic Frontier Foundation (2019)
<br> Read the whole thing.

[Deepfakes and American Law](https://www.davispoliticalreview.com/article/deepfakes-and-american-law)
<br> Abigail Loomis, Davis Political Review (2022).
<br> Read the whole thing.

[As Deepfakes Flourish, Countries Struggle With Response](https://www.nytimes.com/2023/01/22/business/media/deepfake-regulation-difficulty.html)
<br> Tiffany Hsu, N.Y. Times (2023)
<br> Read the whole thing.


## Lesson 09 - Mar. 29

### Large Language Models

The main assignment for this week is to experiment with Chat-GPT. You will need to creat an account with Open AI, but you can access Chat-GPT in your browser at: [https://chat.openai.com/chat](https://chat.openai.com/chat). As you go through your week, just keep it open as a tab in your browser, and experiment with using the tool to answer different questions. In particular, explore how it might be used for law school and legal tasks. Watch [this short video](https://www.youtube.com/watch?v=SbgJDL4DJ7M)  to learn how to provide ChatGPT with stronger prompts.

What are the possible benefits and drawbacks of large language models like GPT-4 for legal education and the legal profession? How can law schools best integrate these technologies into legal education? How can lawyers best integrate these technologies into legal work?

How might the widespread adoption of large language models in the legal profession affect the job market for lawyers and other legal professionals? Will these technologies complement or replace traditional legal roles?

To what extent should large language models be regulated within the legal profession? Can large language models be held accountable for providing incorrect or misleading legal advice? How can we ensure that AI technologies maintain the ethical standards of the legal profession?

Videos:

[How ChatGPT Works Technically For Beginners - YouTube](https://www.youtube.com/watch?v=uCIa6V4uF84)

[A Massive Upgrade To ChatGPT! (This is Crazy) - YouTube](https://www.youtube.com/watch?v=ZSfwgKDcGKY)

[Microsoft's AI Future of Work Event: Everything Revealed in 8 Minutes - YouTube](https://www.youtube.com/watch?v=VqhDnaqhnd4)

[We tried to compete with AI... [AI vs. ARCHITECT] - YouTube](https://www.youtube.com/watch?v=N709ZrxoIP0)
<br> You can skim through parts of this video, but it is an interesting test case in an adjacent field.

Readings:

[**DOWNLOAD ALL READINGS FOR LESSON 09**](Lesson09.zip)

[You Can Have the Blue Pill or the Red Pill, and We’re Out of Blue Pills](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html)
<br> Yuval Harari, Tristan Harris and Aza Raskin, N.Y. Times (2023).
<br> Read the whole thing.

[The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html?action=click&module=RelatedLinks&pgtype=Article)
<br> Noam Chomsky, Ian Roberts and Jeffrey Watumull, N.Y. Times (2023).
<br> Read the whole thing.

[The Implications of ChatGPT for Legal Services and Society](https://clp.law.harvard.edu/knowledge-hub/magazine/issues/generative-ai-in-the-legal-profession/the-implications-of-chatgpt-for-legal-services-and-society/)
<br> Andrew Perlman, Harvard Law School Center on the Legal Profession (2022)
<br> Read the whole thing.

[New GPT-Based Chat App from LawDroid Is A Lawyer's 'Copilot' for Research, Drafting, Brainstorming and More | LawSites](https://www.lawnext.com/2023/01/new-gpt-based-chat-app-from-lawdroid-is-a-lawyers-copilot-for-research-drafting-brainstorming-and-more.html)
<br> Bob Ambrogi, LawNext (2023).
<br> Read the whole thing.

[Can AI replace patent attorneys? - HGF](https://www.hgf.com/news/can-ai-replace-patent-attorneys/)
<br> Mark Sellick, HGF (2022)
<br> Read the whole thing.

[Will ChatGPT Bring AI to Law Firms? Not Anytime Soon.](https://news.bloomberglaw.com/bloomberg-law-analysis/analysis-will-chatgpt-bring-ai-to-law-firms-not-anytime-soon)
<br> Thomas Bacas, BloombergLaw (2022).
<br> Read the whole thing.

[Evaluating The Legal Ethics Of A ChatGPT-Authored Motion](https://www.law360.com/articles/1567985/evaluating-the-legal-ethics-of-a-chatgpt-authored-motion)
<br> Aimee Furness and Sam Mallick, Law360 (2023).
<br> Read the whole thing.




## Lesson 10 - Apr. 5

### Critical Approaches

In this class we’ll be examining critical approaches to algorithmic fairness that challenge the assumptions of the literature we’ve read so far and offer sometimes radical reconceptions of the role that algorithms can play in law and society.

As you work through the readings this week, take note of what critiques and perspectives resonate with you — even if you disagree with the broader argument of an article. In our class discussion, we’ll work on synthesizing these critiques and continuing the work of imagining algorithmic alternatives.  

Readings:

[**DOWNLOAD ALL READINGS FOR LESSON 10**](Lesson10.zip)

[Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness](https://link.springer.com/article/10.1007/s13347-022-00584-6)
<br> Ben Green, Philosophy & Technology (2022).
<br> Read the whole thing.

[On Missing Data Sets](https://github.com/MimiOnuoha/missing-datasets)
<br> Mimi Onuoha, Github Repository (2018).
<br> Read the whole thing.

[Algorithmic Reparation](http://journals.sagepub.com/doi/10.1177/20539517211044808)
<br> Jenny Davis, Apryl Williams, & Michael W. Yang, Big Data & Society (2021).
<br> Read the whole thing.

White Collar Risk Zones
<br> Sam Lavigne, et al., The New Inquiry, (2017). 
<br> Visit the [website](https://whitecollar.thenewinquiry.com/) and read the [whitepaper](https://whitecollar.thenewinquiry.com/static/whitepaper.pdf)

## Lesson 11 - Apr. 12

### The Future

_Readings to be determined_


## Lesson 12 - Apr. 19

### Student presentations

1 - Kevin 

2 - Amara

3 - Soundarya


## Lesson 13 - Apr. 26

### Student presentations

1 - Jake

2 - Monica

3 - Prince



[]:	
[2]:	https://chat.openai.com/chat
[3]:	https://openai.com/dall-e-2/
[4]:	https://epic.org/issues/ai/ai-in-the-criminal-justice-system/
[5]:	https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html
[6]:	https://www.washingtonpost.com/crime-law/2021/12/14/crime-prevention-location-analysis/
[7]:	https://www.propublica.org/article/chicagos-race-neutral-traffic-cameras-ticket-black-and-latino-drivers-the-most?token=d6qqzFPQ19VGp5Qo6NiWBKiq0K33UMvJ
[8]:	https://techcrunch.com/2021/05/18/uptrust-raises-2m-to-fight-the-billions-of-dollars-wasted-on-useless-mass-incarceration/
[9]:	https://digitalcommons.law.scu.edu/lawreview/vol52/iss4/6/
[10]:	https://scholarship.kentlaw.iit.edu/cgi/viewcontent.cgi?article=4192&context=cklawreview
[12]:	https://hastie.su.domains/ISLR2/ISLRv2_website.pdf
[13]:	https://anatomyof.ai/
[14]:	https://www.cc.gatech.edu/~beki/cs4001/Winner.pdf
[15]:	https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=2147&context=journal_articles
[16]:	http://illinoisjltp.com/journal/wp-content/uploads/2018/12/Jones.pdf

[17]:	https://digitalcommons.law.seattleu.edu/cgi/viewcontent.cgi?article=1757&context=faculty




## Lesson 05 - Feb. 15
### Prediction and probability
- What can be learned through contrasts between traditional law and emerging uses of probability within old legal forms and within new processes? 
- What should be the guidelines or restrictions over the use of the new tools?
Philip Dawid, “On Individual Risk,” Synthese 194 (9):3445-3474 (2017)
Barbara Underwood, _Law and the Crystal Ball_, 88 Yale L.J. 1408 (1979). Read pages 1409-1420
Shima Baradaran, _Race, Prediction, and Discretion_, 81 Geo. Wash. L. Rev. 157 (2013). Read introduction, pages 159-64.
John Monahan, _The Prediction of Violent Behavior: Toward a Second Generation of Theory and Policy_, 141 American Journal of Psychiatry 10 (1984). Read the whole thing, pages 10-15.
Vincent Chiao, _Predicting Proportionality: The Case for Algorithmic Sentencing_, 37 Criminal Justice Ethics 238 (2018). Read introduction, pages 238-40.
Elish and Boyd, _Situating methods in the magic of Big Data and AI_, 85 Communication Monographs 57 (2018). Read the introduction pages 57-58 and pages 67-72, starting with “Faith in Prediction.”
Gary L. Wells, “Naked Statistical Evidence of Liability: Is Subjective Probability Enough?” J. PERSONALITY AND SOCIAL PSYCH. 62:3, pp. 739-752 (1992)

## Lesson 06 - Feb. 22
### Case study on risk assessments
State of Wisconsin v. Eric Loomis (2016). Please read paragraphs 11-28 and 67-74.
Julia Angwin, et al., “Machine Bias,” Pro Publica (May 22, 2016), https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
Anthony W. Flores et al., “False Positives, False Negatives, and False Analyses: A Rejoinder to ‘Machine Bias: There’s Software Used Across the Country to Predict Future Criminals. And It’s Biased Against Blacks,’” 80:2 Federal Probation (Sept. 2016)
“ProPublica Responds to Company’s Critique of Machine Bias Story” by Julia
Angwin and Jeff Larson (ProPublica, 2016)
“Inherent Trade-Offs in the Fair Determination of Risk Scores” by Jon Kleinberg, Sendhil Mullainathan, et al. (ArXiv, 2016). Please read Introduction (p.1-3), Section 1.3, and Conclusion.
The Leadership Conference on Civil and Human Rights, _More than 100 Civil Rights, Digital Justice, and Community-Based Organizations Raise Concerns About Pretrial Risk Assessment_ (2018).
Letter and Statement re: Technical Flaws of Pretrial Risk Assessments Raise Grave Concerns (July 8, 2019)
Alex Chohlas-Wood, _Understanding risk assessment instruments in criminal justice_, Brookings Institute (June 19, 2020), [https://www.brookings.edu/research/understanding-risk-assessment-instruments-in-criminal-justice/][15].
The Pretrial Justice Institute, Update Position on Pretrial Risk Assessments Tools (2020).
James Austin, Sarah L Desmarais & John Monahan, Open Letter to the Pretrial Justice Institute, [http://www.jfa-associates.com/publications/Open%20Letter%20to%20the%20Pretrial%20Justice%20Institute.pdf][16] 
Sandra G. Mayson, _Bias In, Bias Out,_ 128 Yale L.J. 2218 (2019). You are only required to read the introduction, but you can read more if you’d like.
Sharad Goel et al., _The Accuracy, Equity, and Jurisprudence of Criminal Risk Assessment_, (2018) [https://www.ssrn.com/abstract=3306723][17]. Read pages 1-4, 8-12.
Megan T Stevenson & Christopher Slobogin, _Algorithmic Risk Assessments and The Double-edged Sword of Youth_ (2018). Read the introduction, page 1-3.

## Lesson 07 - Mar. 1
### Transparency, interpretability, and explainability
In this session we will discuss different approaches to achieve explainability, both from a legal and technical perspective. We will learn about the difference between interpretable algorithms and non-interpretable algorithms, and the difference between transparency ex-ante and transparency ex-post including different auditing methods. We will also discuss the tradeoff between transparency and accuracy, and how balance between the two can be achieved. We will match between different transparency methods and their relevant policy domains, and become familiar with legal concepts such as due process and fair trial; as well as the legal limitations that demand a certain form of transparency. 
- Does a requirement of transparency or explanation in the use of algorithms in decision-making promote fairness? 
- How would it work and what would be limitations? 
- 
“Artificial Intelligence’s ‘Black Box’ Is Nothing to Fear” by Vijay Pande (The New
York Times, 2018)



Aziz Z. Huq, Constitutional Rights in the Machine Learning State, 105 Cornell. L. Rev. (2020)


Paul V. de Laat, “Algorithmic Decision-Making Based on Machine Learning from Big Data: Can Transparency Restore Accountability?,” 47 SIGCAS Computers and Society 39 (2017), https://www.researchgate.net/publication/321017507_Algorithmic_Decision-Making_Based_on_Machine_Learning_from_Big_Data_Can_Transparency_Restore_Accountability
Cliff Kuang, “Can A.I. Be Taught to Explain Itself?,” N.Y. Times Magazine (Nov. 21, 2017), https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html
Julia Powles, “New York City’s Bold, Flawed Attempt to Make Algorithms Accountable,” New Yorker (Dec. 20, 2017), https://www.newyorker.com/tech/annals-of-technology/new-york-citys-bold-flawed-attempt-to-make-algorithms-accountable


## Lesson 08 - Mar. 22
### Regulation Part One
This class and the next will exam legal regimes that could be used to govern or regulate the use of algorithms. Our first class will examine the “Blueprint for an A.I. Bill of Rights” that the White House put out this past fall and also the challenge of regulating deep fakes.

As A.I. and machine learning proliferates, what regulations are required? Are our institutions up to the task or is technology’s disruptive power overblown? Where might governmental oversight succeed and where might it fail? What would underegulation and overregulation look like in this space? How could we measure it? What existing rights should the government protect? What new rights ought to be protected in an age of automation?

[**DOWNLOAD ALL READINGS FOR LESSON 08**](Lesson08.zip)

Please note that the download link above does not include the assigned podcast episode in the .zip file.

[Podcast: Suresh Venkatasubramanian: An AI Bill of Rights](https://thegradientpub.substack.com/p/suresh-venkatasubramanian-an-ai-bill#details)
<br> The Gradient, (2023).
<br> Listen from 43:50 to the end. But feel free to listen to whole thing if you want, lots of good stuff.

[Blueprint for an A.I. Bill of Rights](https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf)
<br> Read pages 5-7, 15-29, 40-52.

[DeepFakes: A Looming Challenge for Privacy, Democracy, and National Security](https://scholarship.law.bu.edu/cgi/viewcontent.cgi?article=1640&context=faculty_scholarship)
<br> Danielle K. Citron & Robert Chesney, Calif. L. Rev. (2019) 
<br> Read 1768-1786 (Section II: Costs & Benefits).

[Responding to Deepfakes and Disinformation](https://www.theregreview.org/2021/08/14/saturday-seminar-responding-deepfakes-disinformation/)
<br> Soojin Jeong, Margaret Sturtevant, & Karis Stephen, The Regulatory Review (2021).
<br> Read the whole thing.

[Congress Should Not Rush to Regulate Deepfakes](https://www.eff.org/deeplinks/2019/06/congress-should-not-rush-regulate-deepfakes)
<br> Hayley Tsukayama, India Mckinney, & Jamie Williams, Electronic Frontier Foundation (2019)
<br> Read the whole thing.

[Deepfakes and American Law](https://www.davispoliticalreview.com/article/deepfakes-and-american-law)
<br> Abigail Loomis, Davis Political Review (2022).
<br> Read the whole thing.

[As Deepfakes Flourish, Countries Struggle With Response](https://www.nytimes.com/2023/01/22/business/media/deepfake-regulation-difficulty.html)
<br> Tiffany Hsu, N.Y. Times (2023)
<br> Read the whole thing.









## Lesson 09 - Mar. 29
### Regulation Part Two


Our second class on regulating algorithms will focus on product liability, using self-driving cars as our case study. Product liability emerged, in part, from the increasing complexity of the supply chain of modern goods and the inherent harm certain products could cause. Is the same approach — or an analogous one — appropriate for dealing with the increasing complexity of algorithms? Or should algorithms be treated like human services? Is there a viable third option, such as universal insurance for harms caused by autonomous vehicles?

Product liability in general, and strict product liability specifically, represent an attempt to regulate the creation and sale of goods by imposing liability for harms caused. Is a regulation-by-incentive approach effective? Is it appropriate for the regulation of algorithms? Where might incentives to create safe, ethical algorithms and artificial intelligences break down? What are other model of assigning redress for the harms caused by technologies such as autonomous vehicles?


Jess Whittlestone, Rune Nyrup, Anna Alexandrova and Stephen Cave, [The Role and Limits of Principles in AI Ethics: Towards A Focus on Tensions][22], AIES19 Proceedings of the AAAI/ACM Conference on AI, Ethics and Society

Gary Marchant and Rachel Lindor, [_The Coming Collision Between Autonomous Vehicles and the Liability System_][23], 52 Santa Clara L. Rev. 1321 (2012) (read 1321-1330)
- Karni A. Chagal-Feferkorn, [_Am I an Algorithm or a Product? When Products Liability Should Apply to Algorithmic Decision-Makers_][24], 30 Stan. L. & Pol'y Rev. 61 (2019) (read pp 70-72, 77-86)

- Hin-Yan Liu, [_Irresponsibilities, Inequalities and Injustice for Autonomous Vehicles_][25], 19 Ethics Info. Tech. 193 (2017) (read pp 194-200)
- 
- Hana Creger, [_How Self-Driving Cars Could Harm Marginalized Communities_][26], Salon (March 5, 2019) (read all)




## Lesson 10 - Apr. 5
### Litigation
In this class session, we'll be looking at the impact of algorithms in three areas of decision-making that are traditionally protected by civil rights laws: housing, lending, and employment. In the first part of class, we'll consider why private actors might want to use algorithms in housing, lending, and employment decision-making and how those uses might interact with civil rights statutes. On one hand, it seems like algorithmic decision-making is a cure for intentional and unintentional discrimination in _human_ decision-making. On the other hand, empirical studies show that algorithmic decision-making can exhibit bias against protected characteristics such as race or gender, even when these characteristics have been scrubbed from input datasets. What are the tradeoffs between algorithmic and human decision-making when it comes to decisions that disparately impact protected classes? Do we (or should we) think about these tradeoffs differently in the areas of housing, lending, and employment? Readings for this part of class are:

For the second part of class, we'll look at potential legal interventions that could address, at least partially, the issue of algorithmic discrimination. Assuming that we find _some_ benefit to algorithmic decision-making (and thus don't opt for an out-right ban), how do we preserve the good while regulating the bad? Should a regulatory agency be nominated - or created - to oversee the deployment of algorithms in areas protected by civil rights laws? Should we create a private right of action against algorithmic discrimination? Or are existing civil rights laws sufficient to address these harms? Readings for this section of class are:
- Matthew Adam Bruckner, [_The Promise and Perils of Algorithmic Lenders’ Use of Big Data_][30], 93 Chi.-Kent L. Rev. 3 (2018) (read pp 31-38, skim pp 38-56)
- Ifeoma Ajunwa, [_The Paradox of Automation as Anti-Bias Intervention_][31], 41 Cardozo L. Rev. 1671 (2020) (skim pp 1720-1726, read pp 1726-1734)
- Staff, [_Booker, Wyden, Clarke Introduce Bill Requiring Companies To Target Bias In Corporate Algorithm_][32]_s_ (April 10, 2019) (read all)
- Sigal Samuel, [_10 Things We Should All Demand from Big Tech Right Now_][33], Vox (May 29, 2019) (read all)
 Steve Ritter, [_The U.S. Urgently Needs an AI Bill of Rights_][34], Fortune (Nov. 12, 2021)
 A.I. Bill of Rights



## Lesson 11 - Apr. 12
### The Future


Dorothy E. Roberts, _Digitizing the Carceral State_, 132 Harv. L. Rev. 1695 (2019). Read 1695-1699, 1721-1728.

[35].

“The Metamorphosis” by Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher (The Atlantic, 2019)

# Student Presentations
## Lesson 12 - Apr. 19
- Student presentations
## Lesson 13 - Apr. 26
- Student presentations




[1]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?wrap=1
[2]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?download_frd=1
[3]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?wrap=1
[4]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?download_frd=1
[5]:	https://canvas.harvard.edu/courses/52624/files/6298539/download?wrap=1
[6]:	https://canvas.harvard.edu/courses/52624/files/6298539/download?wrap=1
[7]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?wrap=1
[8]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[9]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?wrap=1
[10]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[11]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[12]:	https://hbr.org/2018/07/want-less-biased-decisions-use-algorithms
[15]:	https://www.brookings.edu/research/understanding-risk-assessment-instruments-in-criminal-justice/
[16]:	http://www.jfa-associates.com/publications/Open%20Letter%20to%20the%20Pretrial%20Justice%20Institute.pdf
[17]:	https://www.ssrn.com/abstract=3306723
[18]:	https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3453632
[21]:	https://people.csail.mit.edu/pkrafft/papers/critplat-policy-vs-practice.pdf
[22]:	http://lcfi.ac.uk/media/uploads/files/AIES-19_paper_188_Whittlestone_Nyrup_Alexandrova_Cave.pdf
[23]:	https://digitalcommons.law.scu.edu/lawreview/vol52/iss4/6/
[24]:	https://canvas.harvard.edu/courses/97168/files/14213843?wrap=1
[25]:	https://canvas.harvard.edu/courses/97168/files/14136220?wrap=1
[26]:	https://www.salon.com/2019/03/05/how-self-driving-cars-could-harm-marginalized-communities_partner/
[27]:	https://www.aclu.org/legal-document/community-control-over-police-surveillance-ccops-model-bill
[28]:	https://scholarship.kentlaw.iit.edu/cgi/viewcontent.cgi?article=4192&context=cklawreview
[29]:	http://cardozolawreview.com/wp-content/uploads/2020/10/1.-Ajunwa.41.5.6.FINAL-3.pdf
[30]:	https://scholarship.kentlaw.iit.edu/cgi/viewcontent.cgi?article=4192&context=cklawreview
[31]:	http://cardozolawreview.com/wp-content/uploads/2020/10/1.-Ajunwa.41.5.6.FINAL-3.pdf
[32]:	https://www.booker.senate.gov/news/press/booker-wyden-clarke-introduce-bill-requiring-companies-to-target-bias-in-corporate-algorithms
[33]:	https://www.vox.com/the-highlight/2019/5/22/18273284/ai-algorithmic-bill-of-rights-accountability-transparency-consent-bias
[34]:	https://fortune.com/2021/11/12/ai-bill-of-rights-biden-artificial-intelligence-steve-ritter-mitek-systems/
[35]:	https://lpeproject.org/blog/algorithmic-imaginaries-the-political-limits-of-legal-and-computational-reasoning
[36]:	https://whitecollar.thenewinquiry.com/
[37]:	https://whitecollar.thenewinquiry.com/static/whitepaper.pdf