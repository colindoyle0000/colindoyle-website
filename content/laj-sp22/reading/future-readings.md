---
# Title, summary, and page position.
linktitle: Future Reading Assignments
summary: Assigned reading for class, organized chronologically.
weight: 20
# icon: book-reader
# icon\_pack: fas
draft: true
# Page metadata.
title: Reading Assignments
date: '2022-08-14T00:00:00Z'
# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
type: book # Do not modify.
toc: true
---






## Lesson 05 - Feb. 15
### Prediction and probability
- What can be learned through contrasts between traditional law and emerging uses of probability within old legal forms and within new processes? 
- What should be the guidelines or restrictions over the use of the new tools?
Philip Dawid, “On Individual Risk,” Synthese 194 (9):3445-3474 (2017)
Barbara Underwood, _Law and the Crystal Ball_, 88 Yale L.J. 1408 (1979). Read pages 1409-1420
Shima Baradaran, _Race, Prediction, and Discretion_, 81 Geo. Wash. L. Rev. 157 (2013). Read introduction, pages 159-64.
John Monahan, _The Prediction of Violent Behavior: Toward a Second Generation of Theory and Policy_, 141 American Journal of Psychiatry 10 (1984). Read the whole thing, pages 10-15.
Vincent Chiao, _Predicting Proportionality: The Case for Algorithmic Sentencing_, 37 Criminal Justice Ethics 238 (2018). Read introduction, pages 238-40.
Elish and Boyd, _Situating methods in the magic of Big Data and AI_, 85 Communication Monographs 57 (2018). Read the introduction pages 57-58 and pages 67-72, starting with “Faith in Prediction.”
Gary L. Wells, “Naked Statistical Evidence of Liability: Is Subjective Probability Enough?” J. PERSONALITY AND SOCIAL PSYCH. 62:3, pp. 739-752 (1992)

## Lesson 06 - Feb. 22
### Case study on risk assessments
State of Wisconsin v. Eric Loomis (2016). Please read paragraphs 11-28 and 67-74.
Julia Angwin, et al., “Machine Bias,” Pro Publica (May 22, 2016), https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
Anthony W. Flores et al., “False Positives, False Negatives, and False Analyses: A Rejoinder to ‘Machine Bias: There’s Software Used Across the Country to Predict Future Criminals. And It’s Biased Against Blacks,’” 80:2 Federal Probation (Sept. 2016)
“ProPublica Responds to Company’s Critique of Machine Bias Story” by Julia
Angwin and Jeff Larson (ProPublica, 2016)
“Inherent Trade-Offs in the Fair Determination of Risk Scores” by Jon Kleinberg, Sendhil Mullainathan, et al. (ArXiv, 2016). Please read Introduction (p.1-3), Section 1.3, and Conclusion.
The Leadership Conference on Civil and Human Rights, _More than 100 Civil Rights, Digital Justice, and Community-Based Organizations Raise Concerns About Pretrial Risk Assessment_ (2018).
Letter and Statement re: Technical Flaws of Pretrial Risk Assessments Raise Grave Concerns (July 8, 2019)
Alex Chohlas-Wood, _Understanding risk assessment instruments in criminal justice_, Brookings Institute (June 19, 2020), [https://www.brookings.edu/research/understanding-risk-assessment-instruments-in-criminal-justice/][15].
The Pretrial Justice Institute, Update Position on Pretrial Risk Assessments Tools (2020).
James Austin, Sarah L Desmarais & John Monahan, Open Letter to the Pretrial Justice Institute, [http://www.jfa-associates.com/publications/Open%20Letter%20to%20the%20Pretrial%20Justice%20Institute.pdf][16] 
Sandra G. Mayson, _Bias In, Bias Out,_ 128 Yale L.J. 2218 (2019). You are only required to read the introduction, but you can read more if you’d like.
Sharad Goel et al., _The Accuracy, Equity, and Jurisprudence of Criminal Risk Assessment_, (2018) [https://www.ssrn.com/abstract=3306723][17]. Read pages 1-4, 8-12.
Megan T Stevenson & Christopher Slobogin, _Algorithmic Risk Assessments and The Double-edged Sword of Youth_ (2018). Read the introduction, page 1-3.

## Lesson 07 - Mar. 1
### Transparency, interpretability, and explainability
In this session we will discuss different approaches to achieve explainability, both from a legal and technical perspective. We will learn about the difference between interpretable algorithms and non-interpretable algorithms, and the difference between transparency ex-ante and transparency ex-post including different auditing methods. We will also discuss the tradeoff between transparency and accuracy, and how balance between the two can be achieved. We will match between different transparency methods and their relevant policy domains, and become familiar with legal concepts such as due process and fair trial; as well as the legal limitations that demand a certain form of transparency. 
- Does a requirement of transparency or explanation in the use of algorithms in decision-making promote fairness? 
- How would it work and what would be limitations? 
- 
“Artificial Intelligence’s ‘Black Box’ Is Nothing to Fear” by Vijay Pande (The New
York Times, 2018)



Aziz Z. Huq, Constitutional Rights in the Machine Learning State, 105 Cornell. L. Rev. (2020)


Paul V. de Laat, “Algorithmic Decision-Making Based on Machine Learning from Big Data: Can Transparency Restore Accountability?,” 47 SIGCAS Computers and Society 39 (2017), https://www.researchgate.net/publication/321017507_Algorithmic_Decision-Making_Based_on_Machine_Learning_from_Big_Data_Can_Transparency_Restore_Accountability
Cliff Kuang, “Can A.I. Be Taught to Explain Itself?,” N.Y. Times Magazine (Nov. 21, 2017), https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html
Julia Powles, “New York City’s Bold, Flawed Attempt to Make Algorithms Accountable,” New Yorker (Dec. 20, 2017), https://www.newyorker.com/tech/annals-of-technology/new-york-citys-bold-flawed-attempt-to-make-algorithms-accountable

## Lesson 08 - Mar. 15
### Accountability
A major question when inserting AI technologies in routine applications is whether there should be a human validator or supervisor and how human intervention can take place. The present paradigm in complex human-machine interfaces is that the human operator should definitely be granted to take over the control of the system in any situation. This important statement can be supported with ethical and social considerations which affect the acceptability of the technology. However, errors of the operators in the perception of the environment are quite common and may have dramatic consequences in transportation for instance. Therefore the discussion should be enriched with concepts from cognitive psychology and neurosciences in order to cover all aspects of risk assessment and management, including penal responsibility. 
_Readings:_
Jon Kleinberg et al., “Human Decisions and Machine Predictions,” Quarterly Journal of Economics (2018), pp. 237-293
Cynthia Rudin, “Algorithms and Justice: Scrapping the ‘Black Box,’” The ALI Advisor, (Jan. 30, 2018)
Crootof paper?
Carroll Seron and Susan S. Silbey, The Dialectic Between Expert Knowledge and Professional Discretion: Accreditation, Social Control, and the Limits of Instrumental Knowledge, 1 Engineering Studies 101 (July 2009), https://www.researchgate.net/publication/245495032_The_dialectic_between_expert_knowledge_and_professional_discretion_Accreditation_social_control_and_the_limits_of_instrumental_logic

## Lesson 09 - Mar. 22
### Regulation
This class will exam legal regimes that could be used to govern or regulate the use of algorithms. We'll start with product liability, using autonomous vehicles (also known as self-driving cars) as our case study. Product liability emerged, in part, from the increasing complexity of the supply chain of modern goods and the inherent harm certain products could cause. Is the same approach--or an analogous one--appropriate for dealing with the increasing complexity of algorithms? Or should algorithms be treated like human services? Is there a viable third option, such as universal insurance for harms caused by autonomous vehicles?
Product liability in general, and strict product liability specifically, represent an attempt to regulate the creation and sale of goods by imposing liability for harms caused. Is a regulation-by-incentive approach effective? Is it appropriate for the regulation of algorithms? Where might incentives to create safe, ethical algorithms and artificial intelligences break down? What are other model of assigning redress for the harms caused by technologies such as autonomous vehicles?


Jonas Schuett , [Defining the Scope of AI Regulation][18], (2019) 

“DeepFakes: A Looming Challenge for Privacy, Democracy, and National Security”
by Citron & Chesney (Scholarly Common at BU, 2019) Read Section II: Costs &
Benefits (1768-1786) [PERMA]()

“AI is mastering language; should we trust what it says?” by Steven Johnson
(New York Times Magazine, 2022) [PERMA]()


 Peter Krafft, Meg Young, Michael Katell, Karen Huang, and Ghislain Bugingo,, [Defining AI in Policy versus Practice][21], AIES 20: Proceedings of the AAAI/ACM Conference on AI, Ethics and Society. 

Jess Whittlestone, Rune Nyrup, Anna Alexandrova and Stephen Cave, [The Role and Limits of Principles in AI Ethics: Towards A Focus on Tensions][22], AIES19 Proceedings of the AAAI/ACM Conference on AI, Ethics and Society

Gary Marchant and Rachel Lindor, [_The Coming Collision Between Autonomous Vehicles and the Liability System_][23], 52 Santa Clara L. Rev. 1321 (2012) (read 1321-1330)
- Karni A. Chagal-Feferkorn, [_Am I an Algorithm or a Product? When Products Liability Should Apply to Algorithmic Decision-Makers_][24], 30 Stan. L. & Pol'y Rev. 61 (2019) (read pp 70-72, 77-86)

- Hin-Yan Liu, [_Irresponsibilities, Inequalities and Injustice for Autonomous Vehicles_][25], 19 Ethics Info. Tech. 193 (2017) (read pp 194-200)
- Hana Creger, [_How Self-Driving Cars Could Harm Marginalized Communities_][26], Salon (March 5, 2019) (read all)

Matthew Tokson, _The Aftermath of _Carpenter: _An Empirical Study of Fourth Amendment Law_, 135 Harv. L. Rev. (forthcoming 2022) Read 1-6.
**American Civil Liberties Union, Community Control Over Police Surveillance (CCOPS) Model Bill (2021), **[https://www.aclu.org/legal-document/community-control-over-police-surveillance-ccops-model-bill][27]


## Lesson 10 - Mar. 29
### Litigation
In this class session, we'll be looking at the impact of algorithms in three areas of decision-making that are traditionally protected by civil rights laws: housing, lending, and employment. In the first part of class, we'll consider why private actors might want to use algorithms in housing, lending, and employment decision-making and how those uses might interact with civil rights statutes. On one hand, it seems like algorithmic decision-making is a cure for intentional and unintentional discrimination in _human_ decision-making. On the other hand, empirical studies show that algorithmic decision-making can exhibit bias against protected characteristics such as race or gender, even when these characteristics have been scrubbed from input datasets. What are the tradeoffs between algorithmic and human decision-making when it comes to decisions that disparately impact protected classes? Do we (or should we) think about these tradeoffs differently in the areas of housing, lending, and employment? Readings for this part of class are:
- Matthew Adam Bruckner, [_The Promise and Perils of Algorithmic Lenders’ Use of Big Data_][28], 93 Chi.-Kent L. Rev. 3 (2018) (read pp 15-17, skim pp 17-29)
- Ifeoma Ajunwa, [_The Paradox of Automation as Anti-Bias Intervention_][29], 41 Cardozo L. Rev. 1671 (2020) (read pp 1683-1692, skim pp 1692-1707)
For the second part of class, we'll look at potential legal interventions that could address, at least partially, the issue of algorithmic discrimination. Assuming that we find _some_ benefit to algorithmic decision-making (and thus don't opt for an out-right ban), how do we preserve the good while regulating the bad? Should a regulatory agency be nominated - or created - to oversee the deployment of algorithms in areas protected by civil rights laws? Should we create a private right of action against algorithmic discrimination? Or are existing civil rights laws sufficient to address these harms? Readings for this section of class are:
- Matthew Adam Bruckner, [_The Promise and Perils of Algorithmic Lenders’ Use of Big Data_][30], 93 Chi.-Kent L. Rev. 3 (2018) (read pp 31-38, skim pp 38-56)
- Ifeoma Ajunwa, [_The Paradox of Automation as Anti-Bias Intervention_][31], 41 Cardozo L. Rev. 1671 (2020) (skim pp 1720-1726, read pp 1726-1734)
- Staff, [_Booker, Wyden, Clarke Introduce Bill Requiring Companies To Target Bias In Corporate Algorithm_][32]_s_ (April 10, 2019) (read all)
- Sigal Samuel, [_10 Things We Should All Demand from Big Tech Right Now_][33], Vox (May 29, 2019) (read all)
 Steve Ritter, [_The U.S. Urgently Needs an AI Bill of Rights_][34], Fortune (Nov. 12, 2021)
A.I. Bill of Rights


## Lesson 11 - Apr. 5
### The Future
Elish and Boyd, _Situating methods in the magic of Big Data and AI_, 85 Communication Monographs 57 (2018). Read the introduction pages 57-58 and pages 67-72, starting with “Faith in Prediction.”
Rediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan, David Robinson, “Roles for Computing in Social Change” https://arxiv.org/pdf/1912.04883.pdf
Dorothy E. Roberts, _Digitizing the Carceral State_, 132 Harv. L. Rev. 1695 (2019). Read 1695-1699, 1721-1728.
Ruha Benjamin, Race After Technology: Abolitionist Tools for the New Jim Code (2019) Read attached excerpt.
Ben Green, _Algorithmic Imaginaries: The Political Limits of Legal and Computational Reasoning_, LPE Project (2021), [https://lpeproject.org/blog/algorithmic-imaginaries-the-political-limits-of-legal-and-computational-reasoning][35].
Sam Lavigne, et al., _White Collar Risk Zones_, The New Inquiry, (Apr. 26, 2017). Visit the website [https://whitecollar.thenewinquiry.com/][36] and read the whitepaper: [https://whitecollar.thenewinquiry.com/static/whitepaper.pdf][37].
Studying Up
Algorithmic Justice League (https://www.ajlunited.org)
“The Metamorphosis” by Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher (The Atlantic, 2019)

# Student Presentations
## Lesson 12 - Apr. 12
- Student presentations
## Lesson 13 - Apr. 19
- Student presentations
- Algorithmic fairness and grading



[1]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?wrap=1
[2]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?download_frd=1
[3]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?wrap=1
[4]:	https://canvas.harvard.edu/courses/52624/files/6238076/download?download_frd=1
[5]:	https://canvas.harvard.edu/courses/52624/files/6298539/download?wrap=1
[6]:	https://canvas.harvard.edu/courses/52624/files/6298539/download?wrap=1
[7]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?wrap=1
[8]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[9]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?wrap=1
[10]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[11]:	https://canvas.harvard.edu/courses/52624/files/6259925/download?download_frd=1
[12]:	https://hbr.org/2018/07/want-less-biased-decisions-use-algorithms
[15]:	https://www.brookings.edu/research/understanding-risk-assessment-instruments-in-criminal-justice/
[16]:	http://www.jfa-associates.com/publications/Open%20Letter%20to%20the%20Pretrial%20Justice%20Institute.pdf
[17]:	https://www.ssrn.com/abstract=3306723
[18]:	https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3453632
[21]:	https://people.csail.mit.edu/pkrafft/papers/critplat-policy-vs-practice.pdf
[22]:	http://lcfi.ac.uk/media/uploads/files/AIES-19_paper_188_Whittlestone_Nyrup_Alexandrova_Cave.pdf
[23]:	https://digitalcommons.law.scu.edu/lawreview/vol52/iss4/6/
[24]:	https://canvas.harvard.edu/courses/97168/files/14213843?wrap=1
[25]:	https://canvas.harvard.edu/courses/97168/files/14136220?wrap=1
[26]:	https://www.salon.com/2019/03/05/how-self-driving-cars-could-harm-marginalized-communities_partner/
[27]:	https://www.aclu.org/legal-document/community-control-over-police-surveillance-ccops-model-bill
[28]:	https://scholarship.kentlaw.iit.edu/cgi/viewcontent.cgi?article=4192&context=cklawreview
[29]:	http://cardozolawreview.com/wp-content/uploads/2020/10/1.-Ajunwa.41.5.6.FINAL-3.pdf
[30]:	https://scholarship.kentlaw.iit.edu/cgi/viewcontent.cgi?article=4192&context=cklawreview
[31]:	http://cardozolawreview.com/wp-content/uploads/2020/10/1.-Ajunwa.41.5.6.FINAL-3.pdf
[32]:	https://www.booker.senate.gov/news/press/booker-wyden-clarke-introduce-bill-requiring-companies-to-target-bias-in-corporate-algorithms
[33]:	https://www.vox.com/the-highlight/2019/5/22/18273284/ai-algorithmic-bill-of-rights-accountability-transparency-consent-bias
[34]:	https://fortune.com/2021/11/12/ai-bill-of-rights-biden-artificial-intelligence-steve-ritter-mitek-systems/
[35]:	https://lpeproject.org/blog/algorithmic-imaginaries-the-political-limits-of-legal-and-computational-reasoning
[36]:	https://whitecollar.thenewinquiry.com/
[37]:	https://whitecollar.thenewinquiry.com/static/whitepaper.pdf